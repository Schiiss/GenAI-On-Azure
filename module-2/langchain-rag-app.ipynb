{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain RAG App ü¶ú\n",
    "\n",
    "Based on our problem statement, we need to build a customer service chatbot that can answer questions based on our product documentation.This is the first itteration of our app and will be itterated on throughout this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries üßë‚Äçüíª\n",
    "\n",
    "- AzureChatOpenAI: Allows us to authenticate and interact with our GPT4o model\n",
    "\n",
    "- AzureAISearchRetriever: An interface that returns documents given an unstructured query using Azure Search\n",
    "\n",
    "- RunnablePassthrough: Allows you to pass inputs unchanged \n",
    "\n",
    "- ChatPromptTemplate: Creates a prompt template to help translate user input and parameters into instructions for a language model\n",
    "\n",
    "- StrOutputParser: Ensures our LLM output is in the form of a string, making it more deterministic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GPT4o ü§ñ\n",
    "\n",
    "Let's connect in to our existing Azure OpenAI instance and more specifically, our GPT4o model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt4o\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Azure Search Retriever üêï\n",
    "\n",
    "A retriever is an interface that returns documents given an unstructured query. In our case, we want to retrieve product information from Azure Search.\n",
    "\n",
    "This is going to help with the 'R' part in RAG or the retrieval part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AzureAISearchRetriever(\n",
    "    content_key=\"content\", top_k=5, index_name=\"products\", api_key=os.getenv(\"AZURE_SEARCH_KEY\"), service_name=\"genai-on-azure-search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our RAG Prompt Template üó£Ô∏è\n",
    "\n",
    "We give our bot a persona as a 'Q&A bot' and instruct it to 'answer questions on the products we sell'.\n",
    "\n",
    "The prompt template takes into two parameters:\n",
    "\n",
    "1. context: the documents returned from the Azure Search retriever\n",
    "\n",
    "2. question: the users original question\n",
    "\n",
    "This is going to help with the 'A' part of RAG or the augmentation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_bot_prompt = \"\"\"You are a Q&A bot and your job is to answer questions on the products we sell\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(customer_bot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LCEL Chain ‚õìÔ∏è\n",
    "\n",
    "Below we leverage the LangChain expression language to 'chain' together our retriever, prompt, LLM (ie: gpt4o), and the StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #1 ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how much is the home theater system?\"\n",
    "print(retrieval_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #1 Follow-up ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"are you sure? can you check again?\"\n",
    "print(retrieval_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #2 ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the cheapest pair of headphones?\"\n",
    "print(retrieval_chain.invoke(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
