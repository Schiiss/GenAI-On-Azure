{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is RAG (Retrieval Augmented Generation)? ü§∑‚Äç‚ôÇÔ∏è\n",
    "\n",
    "- LLM's by default (generally) do not have access to the outside world\n",
    "\n",
    "- RAG is an architecture practice that enables us to retrieve relevant info from another source, leverage that info to augment the LLM's knowledge, and use that to generate a final response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage LangChains GPT4o Abstraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt4o\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Rag Enabled Question\n",
    "\n",
    "Below let's ask a question we know the LLM will not have the answer to since it is outside it's training data (ie: it is too recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"who won the vancouver canucks game on Saturday May 18th 2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Enabled Question\n",
    "\n",
    "Now let's Retrieve (R) some information from a webpage to Augment (A) the LLM's knowledge and Generate (G) a final response\n",
    "\n",
    "Let's leverage LangChains WebBaseLoader to scrape some information from a webpage. In this case, I will leverage the [ESPN webpage](https://www.espn.com/nhl/boxscore/_/gameId/401658461) documenting the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.espn.com/nhl/boxscore/_/gameId/401658461\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take that same data that was scrapped and append it to the back of my prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(f\"who won the vancouver canucks game on Saturday May 18th 2024 based on the below info: {data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
